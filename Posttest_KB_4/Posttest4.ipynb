{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Dataset\n",
    "\n",
    "Dikarenakan ukuran dataset yang terlalu besar(42MB), maka untuk dataset saya upload di gdrive, berikut link Gdrive dataset:\n",
    "\n",
    "[Belgium Population Classification](https://drive.google.com/file/d/1WGAMXm3Pkl7sp2xvdJQPbsOa4Z-MpESc/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimport Library\n",
    "\n",
    "- **'import pandas as pd'**, digunakan untuk membaca dataset csv\n",
    "- **'import numpy as np'**, digunakan saat melakukan standarisasi\n",
    "- **'from sklearn.model_selection import train_test_split'**, digunakan untuk membagi dataset menjadi training set dan testing set\n",
    "- **'from sklearn.impute import SimpleImputer'**, digunakan saat menangani nilai null\n",
    "- **'from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder'**, digunakan saat melakukan normalisasi data, StandardScaler digunakan saat melakukan standarisasi data dan OneHotEncoder digunakan saat melakukan Encoding dengan metode One Hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membaca file csv menggunakan encoding 'latin-1'\n",
    "\n",
    "Encoding default membaca file csv yang digunakan pandas adalah **'UTF-8'**, mengubah encoding pandas menjadi **'latin-1'** agar file bisa dibaca oleh pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BELGIUM_POPULATION_STRUCTURE_2018.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat copy dataset\n",
    "\n",
    "Membuat variabel **'df2'** untuk menampung dataset copy yang nantinya digunakan untuk normalisasi dan standarisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membagi dataset menjadi training set dan testing set dengan proporsi 70:30\n",
    "\n",
    "Membuat variabel **'y'** untuk menampung semua column selain target/label, variabel **'x'** untuk menampung column target/label, dan variabel **'x_train, x_test, y_train, y_test'** untuk menampung semua data train dan test dengan proporsi 70% train dan 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi x_train (325792, 12)\n",
      "Dimensi x_test (139626, 12)\n",
      "Dimensi y_train (325792,)\n",
      "Dimensi y_test (139626,)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(columns=\"NATIONALITY\")\n",
    "y = df.loc[:, \"NATIONALITY\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7)\n",
    "print('Dimensi x_train', x_train.shape)\n",
    "print('Dimensi x_test', x_test.shape)\n",
    "print('Dimensi y_train', y_train.shape)\n",
    "print('Dimensi y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menangani nilai null\n",
    "\n",
    "Sebelum menangani nilai null, kita perlu mengetahui apakah ada nilai null dalam dataset menggunakan **'df.isna().sum()'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUNICIPALITY REFNIS CODE        0\n",
       "MUNICIPALITY NAME               0\n",
       "DISTRICT REFNIS CODE            0\n",
       "DISTRICT NAME                   0\n",
       "PROVINCE REFNIS CODE        21425\n",
       "PROVINCE NAME               21425\n",
       "REGION REFNIS CODE              0\n",
       "REGION NAME                     0\n",
       "GENDER                          0\n",
       "NATIONALITY                     0\n",
       "CIVIL CODE STATUS               0\n",
       "AGE                             0\n",
       "POPULATION                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil diatas, diketahui ada nilai null pada column **'PROVINCE REFNIS CODE'** dan **'PROVINCE NAME'**, untuk mengatasi hal ini kita dapat menggunakan strategy median/modus dalam kasus ini saya menggunakan modus, pertama membuat variabel **'imputer'** untuk menampung fungsi **'SimpelImputer'** yang menggunakan strategy modus dengan menggunakan **'most_frequent'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan penanganan nilai null menggunakan strategy modus/most_frequent pada column **'PROVINCE REFNIS CODE'** dengan menggunakan **'imputer.fit_transform(df[[\"PROVINCE REFNIS CODE\"]])'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PROVINCE REFNIS CODE\"] = imputer.fit_transform(df[[\"PROVINCE REFNIS CODE\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melakukan penanganan nilai null menggunakan strategy modu/most_frequent pada column **'PROVINCE NAME'** dengan menggunakan **'imputer.fit_transform(df[[\"PROVINCE NAME\"]])'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PROVINCE NAME\"] = imputer.fit_transform(df[[\"PROVINCE NAME\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melihat hasil penanganan nilai null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUNICIPALITY REFNIS CODE    0\n",
       "MUNICIPALITY NAME           0\n",
       "DISTRICT REFNIS CODE        0\n",
       "DISTRICT NAME               0\n",
       "PROVINCE REFNIS CODE        0\n",
       "PROVINCE NAME               0\n",
       "REGION REFNIS CODE          0\n",
       "REGION NAME                 0\n",
       "GENDER                      0\n",
       "NATIONALITY                 0\n",
       "CIVIL CODE STATUS           0\n",
       "AGE                         0\n",
       "POPULATION                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari data diatas dapat dilihat bahwa tidak ada lagi data yang bernilai null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menangani Nilai Duplikat\n",
    "\n",
    "Sebelum menangani data duplikat, kita perlu melihat apakah ada data duplikat atau tidak dengan menggunakan **'df.duplicated().sum()'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dikarenakan tidak ada data duplikat, untuk memenuhi ketentuan posttest, maka dilakukan penambahan data yang bernilai duplikat, dalam kasus ini saya mencoba untuk menduplikat record dengan index 43280, 54321, dan 12345 dengan menggunakan **'df = pd.concat([df, df.loc[43280]], ignore_index=True)'**, **'df = pd.concat([df, df.loc[54321]], ignore_index=True)'** dan **'df = pd.concat([df, df.loc[12345]], ignore_index=True)'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df.loc[43280]])\n",
    "df = pd.concat([df, df.loc[54321]])\n",
    "df = pd.concat([df, df.loc[12345]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah menggunakan **'concat'** akan terdapat column tambahan, maka saya gunakan **'df.iloc[:, :-1]'** untuk menghapus column tambahan, karena saya hanya membutuhkan record tambahan yang duplikat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah menambahkan data duplikat, cek apakah data sudah terduplikat atau tidak dengan menggunakan **'df.duplicated().sum()'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil diatas terdapat 11 data duplikat, dengan ini kita dapat melakukan penanganan data duplikat dengan menggunakan **'df.drop_duplicates(inplace=True)'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melihat hasil penanganan nilai duplikat\n",
    "\n",
    "Setelah melakukan penanganan data duplikat, kita bisa melakukan cek kembali apakah masih terdapat data duplikat atau tidak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil diatas sudah tidak ada lagi data yang bernilai duplikat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisasi\n",
    "\n",
    "Melakukan normalisasi menggunakan **MinMaxScaler** pada salah satu attribute, dalam kasus ini saya menggunakannya pada Column **'AGE'**, membuat variabel **'age_normalized'** untuk menampung hasil normalisasi yang menggunakan **'MinMaxScaler().fit_transform(df2[[\"AGE\"]])'** dan membuat variabel **'data'** untuk menampilkan data hasil normalisasi dalam bentuk tabel dengan menggunakan **'pd.DataFrame(age_normalized)'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465413</th>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465414</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465415</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465416</th>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465417</th>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>465418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0       0.39\n",
       "1       0.82\n",
       "2       0.42\n",
       "3       0.63\n",
       "4       0.30\n",
       "...      ...\n",
       "465413  0.64\n",
       "465414  0.67\n",
       "465415  0.74\n",
       "465416  0.81\n",
       "465417  0.63\n",
       "\n",
       "[465418 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_normalized = MinMaxScaler().fit_transform(df2[[\"AGE\"]])\n",
    "data = pd.DataFrame(age_normalized)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarisasi\n",
    "\n",
    "Melakukan standarisasi menggunakan **'StandardScaler()'** pada salah satu attribute, dalam kasus ini saya menggunakannya pada Column **'POPULATION'**, membuat variabel **'population_standard_scaler'** untuk menampung hasil standarisasi yang menggunakan **'StandardScaler().fit_transform(df2[[\"POPULATION\"]])'** dan membuat variabel **'data1'** untuk menampilkan data hasil standarisasi dalam bentuk tabel dengan menggunakan **'pd.DataFrame(population_standard_scaler)'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.275423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.961885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.163815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465413</th>\n",
       "      <td>-0.367747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465414</th>\n",
       "      <td>-0.352060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465415</th>\n",
       "      <td>-0.367747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465416</th>\n",
       "      <td>-0.367747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465417</th>\n",
       "      <td>-0.367747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>465418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0       0.275423\n",
       "1      -0.006945\n",
       "2       0.416606\n",
       "3       3.961885\n",
       "4      -0.163815\n",
       "...          ...\n",
       "465413 -0.367747\n",
       "465414 -0.352060\n",
       "465415 -0.367747\n",
       "465416 -0.367747\n",
       "465417 -0.367747\n",
       "\n",
       "[465418 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_standard_scaler = StandardScaler().fit_transform(df2[[\"POPULATION\"]])\n",
    "data1 = pd.DataFrame(population_standard_scaler)\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengganti tipe data pada salah satu attribute angka\n",
    "\n",
    "Dalam kasus ini mengubah tipe data column **'DISTRICT REFNIS CODE'** menjadi object, menggunakan **'.astype(\"object\")'**, pertama membuat variabel **'tipe_data_object'** untuk menampung hasil perubahan tipe data, kemudian menampilkan tipe data terbaru dari column **'DISTRICT REFNIS CODE'** menggunakan **'tipe_data_object[\"DISTRICT REFNIS CODE\"].dtypes'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipe_data_object = df[[\"DISTRICT REFNIS CODE\"]].astype(\"object\")\n",
    "tipe_data_object[\"DISTRICT REFNIS CODE\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "Melakukan One Hot Encoding pada column **'GENDER'** dengan menggunakan fungsi **'OneHotEncoder(sparse_output=False).fit_transform(df[[\"GENDER\"]])'** dan ditampung di variabel **'gender_encoded'** dan diubah ke bentuk tabel dengan menggunakan **'pd.DataFrame(gender_encoded)'** dan gabung data One Hot ke dataset dengan menggunakan **'df.join(gender_encoded)'** pada variabel **'dataset_onehot'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUNICIPALITY REFNIS CODE</th>\n",
       "      <th>MUNICIPALITY NAME</th>\n",
       "      <th>DISTRICT REFNIS CODE</th>\n",
       "      <th>DISTRICT NAME</th>\n",
       "      <th>PROVINCE REFNIS CODE</th>\n",
       "      <th>PROVINCE NAME</th>\n",
       "      <th>REGION REFNIS CODE</th>\n",
       "      <th>REGION NAME</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>NATIONALITY</th>\n",
       "      <th>CIVIL CODE STATUS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71024.0</td>\n",
       "      <td>Herk-de-Stad</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>F</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71037.0</td>\n",
       "      <td>Lummen</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>82.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71011.0</td>\n",
       "      <td>Diepenbeek</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>F</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71016.0</td>\n",
       "      <td>Genk</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>63.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71017.0</td>\n",
       "      <td>Gingelom</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>F</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71020.0</td>\n",
       "      <td>Halen</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71022.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>50.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>71022.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>40.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71045.0</td>\n",
       "      <td>Nieuwerkerken (Hasselt)</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>71017.0</td>\n",
       "      <td>Gingelom</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Hasselt</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Limburg</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Flemish Region</td>\n",
       "      <td>M</td>\n",
       "      <td>Belgian</td>\n",
       "      <td>Married</td>\n",
       "      <td>57.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUNICIPALITY REFNIS CODE        MUNICIPALITY NAME  DISTRICT REFNIS CODE  \\\n",
       "0                   71024.0             Herk-de-Stad               71000.0   \n",
       "1                   71037.0                   Lummen               71000.0   \n",
       "2                   71011.0               Diepenbeek               71000.0   \n",
       "3                   71016.0                     Genk               71000.0   \n",
       "4                   71017.0                 Gingelom               71000.0   \n",
       "5                   71020.0                    Halen               71000.0   \n",
       "6                   71022.0                  Hasselt               71000.0   \n",
       "7                   71022.0                  Hasselt               71000.0   \n",
       "8                   71045.0  Nieuwerkerken (Hasselt)               71000.0   \n",
       "9                   71017.0                 Gingelom               71000.0   \n",
       "\n",
       "  DISTRICT NAME  PROVINCE REFNIS CODE PROVINCE NAME  REGION REFNIS CODE  \\\n",
       "0       Hasselt               70000.0       Limburg              2000.0   \n",
       "1       Hasselt               70000.0       Limburg              2000.0   \n",
       "2       Hasselt               70000.0       Limburg              2000.0   \n",
       "3       Hasselt               70000.0       Limburg              2000.0   \n",
       "4       Hasselt               70000.0       Limburg              2000.0   \n",
       "5       Hasselt               70000.0       Limburg              2000.0   \n",
       "6       Hasselt               70000.0       Limburg              2000.0   \n",
       "7       Hasselt               70000.0       Limburg              2000.0   \n",
       "8       Hasselt               70000.0       Limburg              2000.0   \n",
       "9       Hasselt               70000.0       Limburg              2000.0   \n",
       "\n",
       "      REGION NAME GENDER NATIONALITY CIVIL CODE STATUS   AGE  POPULATION    0  \\\n",
       "0  Flemish Region      F     Belgian           Married  39.0        42.0  1.0   \n",
       "1  Flemish Region      M     Belgian           Married  82.0        24.0  0.0   \n",
       "2  Flemish Region      F     Belgian           Married  42.0        51.0  1.0   \n",
       "3  Flemish Region      M     Belgian           Married  63.0       277.0  0.0   \n",
       "4  Flemish Region      F     Belgian           Married  30.0        14.0  1.0   \n",
       "5  Flemish Region      M     Belgian           Married  52.0        52.0  0.0   \n",
       "6  Flemish Region      M     Belgian           Married  50.0       283.0  0.0   \n",
       "7  Flemish Region      M     Belgian           Married  40.0       219.0  0.0   \n",
       "8  Flemish Region      M     Belgian           Married  81.0        11.0  0.0   \n",
       "9  Flemish Region      M     Belgian           Married  57.0        38.0  0.0   \n",
       "\n",
       "     1    2  \n",
       "0  0.0  0.0  \n",
       "1  1.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  1.0  0.0  \n",
       "4  0.0  0.0  \n",
       "5  1.0  0.0  \n",
       "6  1.0  0.0  \n",
       "7  1.0  0.0  \n",
       "8  1.0  0.0  \n",
       "9  1.0  0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_encoded = OneHotEncoder(sparse_output=False).fit_transform(df[[\"GENDER\"]])\n",
    "gender_encoded = pd.DataFrame(gender_encoded)\n",
    "dataset_oneHot = df.join(gender_encoded)\n",
    "dataset_oneHot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ikhwan_066",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
